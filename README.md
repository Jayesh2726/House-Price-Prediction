# ğŸ  House Price Prediction â€” Linear Regression & Random Forest

## ğŸ“Œ Project Overview

This project focuses on predicting house prices using supervised machine learning techniques.
We start with **Linear Regression** as the baseline model and later improve the model performance using **RandomForestRegressor** and **Grid Search CV** for hyperparameter tuning.

---

## ğŸ“Š Dataset

The dataset contains features such as:

* **SqFt** â€“ Total square feet
* **Bedrooms**
* **Bathrooms**
* **Offers**
* **Price** â€” *target variable*

Basic preprocessing steps include:

* Handling missing values
* Removing outliers using IQR
* Feature scaling (optional)
* Trainâ€“test splitting

---

## ğŸ”§ Models Used

### 1ï¸âƒ£ **Linear Regression (Baseline Model)**

* Simple and interpretable model
* Achieved ~**70â€“79% RÂ²** depending on outlier treatment
* Evaluation metrics used:

  * **MSE**
  * **RMSE**
  * **MAE**
  * **RÂ² Score**

### 2ï¸âƒ£ **RandomForestRegressor (Improved Model)**

* Handles non-linear relationships
* Reduces overfitting
* Performs feature bagging
* Achieved up to **~79â€“80% RÂ²**

### 3ï¸âƒ£ **Grid Search CV (Hyperparameter Tuning)**

Grid Search was applied on Random Forest to optimize parameters such as:

* `n_estimators`
* `max_depth`
* `min_samples_split`
* `min_samples_leaf`

This further improved performance with:
âœ” Lower MSE
âœ” Lower RMSE
âœ” Slightly better MAE
âœ” Higher RÂ² Score

---

## ğŸ“ˆ Model Evaluation

Metrics used:

* **Mean Squared Error (MSE)**
* **Root Mean Square Error (RMSE)**
* **Mean Absolute Error (MAE)**
* **R-squared (RÂ² Score)**

These metrics helped compare both models and confirm improvement.

---

## ğŸ§ª Prediction

After training the best model, predictions are generated for new input values such as:

```python
model.predict([[SqFt, Bedrooms, Bathrooms, Offers]])
```

---

## ğŸ Conclusion

* **Linear Regression** gave a good baseline performance.
* **RandomForestRegressor** significantly improved accuracy.
* **Grid Search CV** helped fine-tune the model for optimal performance.
* Final model achieved strong prediction accuracy with an RÂ² close to **80%**.
